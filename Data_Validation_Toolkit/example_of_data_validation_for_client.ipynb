{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e8b8ead",
   "metadata": {},
   "source": [
    "# Example Validation Template for a client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9d762f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up environment\n",
    "\n",
    "# importing generic packages \n",
    "from pyathena import connect\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np \n",
    "import warnings\n",
    "import boto3\n",
    "from datetime import datetime, timedelta, date\n",
    "# import bpm data validation package\n",
    "import dash_validation_toolkit \n",
    "# stop warnings\n",
    "import warnings\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# create athena connection to uk data hub\n",
    "athena_conn = connect(s3_staging_dir='s3://bucket_path/',\n",
    "               region_name='region')\n",
    "\n",
    "# Define date variables\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "# Add current week \n",
    "today = datetime.today()\n",
    "this_monday_date = today - timedelta(days = today.weekday()\n",
    "                           , hours = today.hour\n",
    "                           , minutes = today.minute\n",
    "                           , seconds = today.second\n",
    "                           , microseconds = today.microsecond\n",
    "                          )\n",
    "# convert to string\n",
    "this_monday = this_monday_date.strftime('%Y%m%d')\n",
    "\n",
    "# getting last monday date\n",
    "last_monday = this_monday_date - timedelta(days = 7)\n",
    "last_monday = last_monday.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbddbb75",
   "metadata": {},
   "source": [
    "## Client set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a09297b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################  REQUIRES INPUT FROM ANALYST ######################################################################\n",
    "# the string name of the client to be validated\n",
    "validation_client = 'example'\n",
    "# a list of the aws regions the client operates in \n",
    "regions = [\"ap-southeast-1\", \"us-east-1\"]\n",
    "# a list of the prod core databases for the client in their origin region\n",
    "core_databases = [\"core data base\"]\n",
    "# a list of the prod core databases for the client in their origin region\n",
    "zephyr_databases = [\"zephyr image database\"]\n",
    "# Defining the webhook for sending messages to slack:\n",
    "webhook = \"webhook api address\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "78c2ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the clients object for adding warnings and errors to throughout the validation stages:\n",
    "client_object = client(\n",
    "                       client=validation_client, \n",
    "                       regions=regions,\n",
    "                       core_databases=core_databases, \n",
    "                       zephyr_databases=zephyr_databases, \n",
    "                       slack_webhook=webhook, \n",
    "                       connection=athena_conn, \n",
    "                       send_to_slack=True\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf2c24e",
   "metadata": {},
   "source": [
    "## Stage 1 Checks (Regional Prod to Union Comparisons) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "97e0d485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Validation of Production Union tables: Loop through all union tables of a client & ensure all pass stage 1 validations, with any failures or warnings passing to dependency tables.\n",
    "#      i.   1.1 - Check count of each region in prod is correctly represented in aggregated union table \n",
    "#      ii.  1.2 - Check that there are no nulls in region columns of union table - null check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b967c8d5",
   "metadata": {},
   "source": [
    "### Run all Stage 1 checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f1e415",
   "metadata": {},
   "source": [
    "<b> Set up: Create check_set </b> <br>\n",
    "Declare which checks to run for this stage - only checks added as strings below in check_set will be run. \n",
    "> Note: if wanting to skip stage entirely than leave as an empty set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "400af1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_set = {'1.1', '1.2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf732d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check 1.1 (same regional row count):  True 85 menicon_order_configurations jj_prod_union 85 menicon_order_configurations core_apse1_prod\n",
      "Check 1.1 (same regional row count):  True 360 patients jj_prod_union 360 patients core_apse1_prod\n",
      "Check 1.1 (same regional row count):  True 355 menicon_lens_parameters jj_prod_union 355 menicon_lens_parameters core_apse1_prod\n",
      "Check 1.1 (same regional row count):  True 203 organisational_unit_user jj_prod_union 203 organisational_unit_user core_apse1_prod\n",
      "Check 1.1 (same regional row count):  True 113 addresses jj_prod_union 113 addresses core_apse1_prod\n",
      "Check 1.1 (same regional row count):  True 355 menicon_order_items jj_prod_union 355 menicon_order_items core_apse1_prod\n",
      "Check 1.1 (same regional row count):  True 10 ethnicities jj_prod_union 10 ethnicities core_apse1_prod\n",
      "Check 1.1 (same regional row count):  True 0 menicon_ended_reasons jj_prod_union 0 menicon_ended_reasons core_apse1_prod\n",
      "Check 1.1 (same regional row count):  True 251 custom_addresses jj_prod_union 251 custom_addresses core_apse1_prod\n",
      "Check 1.1 (same regional row count):  True 134 forms jj_prod_union 134 forms core_apse1_prod\n",
      "Check 1.1 (same regional row count):  True 314 menicon_journeys jj_prod_union 314 menicon_journeys core_apse1_prod\n",
      "Check 1.1 (same regional row count):  True 26889 ledgers jj_prod_union 26889 ledgers core_apse1_prod\n",
      "Check 1.1 (same regional row count):  True 513 roles jj_prod_union 513 roles core_apse1_prod\n"
     ]
    }
   ],
   "source": [
    "# Running the stage one checks, for the client using stage one driver function, with no user-defined client inputs required :\n",
    "stage_1_driver = stage_1(name='Stage 1', client=client_object, check_set=check_set).run_stage_checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081b38d2",
   "metadata": {},
   "source": [
    "## Stage 2 Checks (Base & FHIR table validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b5922",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Stage 2: Validation of Base and FHIR tables: Loop through all base and FHIR tables for client, ensuring all pass stage 2 validations, with any prior failures/warnings or new failure/warnings carrying across into dependant tables.\n",
    "    #      i.   2.1 - Check that primary key count between union and base/FHIR tables is the same\n",
    "    #      ii.  2.2 - Check that primary key of base/FHIR are all in primary key of union table - distinct primary keys are the same\n",
    "    #      iii. 2.3 - Check that every primary key is unique within base/FHIR tables - for base/FHIR tables this is only the primary id and not the update time\n",
    "    #      iv. 2.4 - Check that defintion look-up tables are up-to-date & not missing new values for FHIR & Base tables\n",
    "    #       v. 2.5 - Check that a particular tracked metric is the expected value - e.g. no. of open consults or missing postcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20276b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up stage 2 parameter Dictionary, containing all check lists for stage - and each list containing all check instances (with custom parameters) to be completed :\n",
    "stage_parameters = { # list for checks 2.1, 2.2, 2.3\n",
    "                     \"source_target_input_list\"   : list(),\n",
    "                     # list for check 2.4\n",
    "                     \"definition_check_list\": list(),\n",
    "                     # list for check 2.5:\n",
    "                     \"track_check_list\" : list()\n",
    "                    } "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7052e1",
   "metadata": {},
   "source": [
    "### Set-up checks 2.1, 2.2, 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c640728e",
   "metadata": {},
   "source": [
    "<b> Set up: Create query list </b> <br>\n",
    "For primary key checks. 2.1-2.3 - this will check that primary key count is same between union and base/fhir tables, check the primary key constraint for each table and that all primary keys are present between both union and base/fhir tables. The input parameters are as follows:\n",
    "\n",
    "> target: the name of the table being tested \n",
    "\n",
    "> target_PK:  an integer representing the index number of the PK for the base/FHIR table e.g. in format 0 (index 0 of base table) - or if composite base/FHIR PK key then a list of column indexes e.g. dim_user PK would be [0,7]\n",
    "\n",
    "> target_PK: the corresponding union query from the 'FROM' downwards only (not select) which would give the PK id equivalent for the corresponding union or source table to compare against  e.g. in the format: \"\"\" FROM jj_prod_union.menicon_encounters \"\"\"]\n",
    "\n",
    "> parent_query: a string representing the name of the corresponding PK column of the union or Source table e.g. in format 'id' OR 'id, region' if composite PK key\n",
    "\n",
    "> prod_ids: a string of the target database table is in - e.g. sandbox or base_tables\n",
    "\n",
    "> targetdbs: a bool True or False to signify whether to complete the unique PK check or not - e.g. for cases where we want to allow breaking of constraints/checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3a86b6",
   "metadata": {},
   "source": [
    "#### (i) Base tables query list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b612d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################  REQUIRES INPUT FROM ANALYST ######################################################################\n",
    "stage_parameters[\"source_target_input_list\"].append( \n",
    "{   \"target\": \"TABLE_name\",\n",
    "    \"target_PK\": 'encounter_id',\n",
    "    \"parent_query\": \"\"\"  FROM   jj_prod_union.menicon_encounters   \"\"\",\n",
    "    \"prod_ids\": 'id',\n",
    "    \"targetdbs\": \"jj_sandbox\" ,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779d48a3",
   "metadata": {},
   "source": [
    "#### (ii) FHIR tables query list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b775a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Dim tables against production/union\n",
    "stage_parameters[\"source_target_input_list\"].append(\n",
    "{   \"target\": \"TABLE_name\",\n",
    "    \"target_PK\": \"column_id\",\n",
    "    \"parent_query\":  \"FROM   TABLE_name.column_id\", \n",
    "    \"prod_ids\": 'id', \n",
    "    \"targetdbs\": \"DATABASE\" \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3ae5ab",
   "metadata": {},
   "source": [
    "### Set-up check 2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad575ce",
   "metadata": {},
   "source": [
    "<b> Create the look-up table list </b><br>\n",
    "For checking no new/uncategorised defintion values in client related look-up tables, and then the parameters below for the check are as follows:\n",
    "\n",
    "> definition: the name of the defintion e.g. ecp role - which will be used to display name of definiton being checked in the output\n",
    "\n",
    "> look_up_database: the string name of the database for which the look-up table is located e.g. jj_sandbox\n",
    "\n",
    "> look_up_table:  the name of the look-up table e.g. in the format: 'ecp_user_roles_LOOK_UP' for JJ (table with the look_up_inclusion_flag for the definition value) \n",
    "\n",
    "> look_up_column: a string with the name of column representing the definition value being monitored - e.g. name in the case of ecp roles\n",
    "\n",
    "> look_up_inclusion_flag:  a string, look-up inclusion flag, which indicates the column used for categorising the look-up value - if none then look-up value column of interest - e.g. name for cost roles or inclusion_flag for ecp_roles\n",
    "\n",
    "> Note: look_up_column and look_up_inclusion_flag should not be the same column, if so consider using the track check with a value set output instead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138b778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################  REQUIRES INPUT FROM ANALYST ######################################################################\n",
    "\n",
    "# Definition 1: Creating check input variables for check 2.4, \n",
    "definition = \"definition name\"\n",
    "stage_parameters[\"definition_check_list\"].append(\n",
    "{   \"definition\": definition,\n",
    "    \"look_up_database\": 'DATABASE',\n",
    "    \"look_up_table\":  \"LOOK_UP_COLUMN\", \n",
    "    \"look_up_column\": 'COLUMN', \n",
    "    \"look_up_inclusion_flag\": \"look_up_inclusion_flag\" \n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27ff312",
   "metadata": {},
   "source": [
    "### Set-up check 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c3c36e",
   "metadata": {},
   "source": [
    "<b> Check for a tracked metric that the it is tracking at its expected value </b> <br>\n",
    "For checking that a tracked metric (e.g. orgs with null countries) has the expected/desired number (e.g. 0) or returns any values from query if a set of values\n",
    "Parameters are as follows:\n",
    "\n",
    "> tracking_name: name of the tracking check\n",
    "\n",
    "> tracking_query: the query string for getting the current count of the tracked thing (e.g. orgs with null country) - need to name either count or set depending on desired query output\n",
    "\n",
    "> expected_result: an integer for what the expected or desired number of this tracked thing should be\n",
    "\n",
    "> track_type: a string indicating whether query output is a count to be compared against number OR a set of values to be shown if not an empty set returned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0a7a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################  REQUIRES INPUT FROM ANALYST ######################################################################\n",
    "                                                                            \n",
    "# setting up input for tracking statistic check\n",
    "tracking_name = \"name of tracking stat\"\n",
    "stage_parameters[\"track_check_list\"].append(\n",
    "{   \"tracking_name\": tracking_name,\n",
    "    \"tracking_query\":  \"\"\"\n",
    "                        SELECT DISTINCT COLUMN_OF_INTEREST AS set\n",
    "                        FROM \"DATABASE\".\"TABLE\" \n",
    "                        \n",
    "                       \"\"\",\n",
    "    \"expected_result\":  0, \n",
    "    \"track_type\": 'set' \n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569b8b8f",
   "metadata": {},
   "source": [
    "### Run all Stage 2 Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdf4410",
   "metadata": {},
   "source": [
    "<b> Set up: Create check_set </b> <br>\n",
    "Declare which checks to run for this stage - only checks added as strings below in check_set will be run. \n",
    "> Note: if wanting to skip stage entirely than leave as an empty set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e221787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_set = {'2.1', '2.2', '2.3', '2.4', '2.5'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39071b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the stage two checks, for the client using stage one driver function, with no user-defined client inputs required :\n",
    "client_object = stage_2(name='Stage 2', client=client_object, check_set=check_set, **stage_parameters).run_stage_checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f57995f",
   "metadata": {},
   "source": [
    "## Stage 3 Checks (Base to Dashboard Comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f4990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Stage 3: Validation of Dashboard tables: For each client, check end-point powerBI dashboard tables, comparing key dashboard statistics against base, checking assumptions & checking business logic\n",
    "    #      i.   3.1 - Check that if a statistic has a select all (except onboarded) that all pathways add up to select all\n",
    "    #      ii.  3.2 - Check that dashboard table statistics count against associated base table is equal\n",
    "    #      iii. 3.3 - Check a cumulative table, if select all than this is equal the overall base statistic total\n",
    "    #      iii. 3.4 - Check for a statistic where all pathways should be same value (e.g. onboarded) that all pathways are equal\n",
    "    #      v.  3.5 - Check for business logic against base tables\n",
    "    #      iv.  3.6 - Within-dashboard comparisons, checking figures in dashboard are the same where they are meant to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1988b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up stage 3 parameter list, containing all check dictionary instances for stage - each check dictionary containing all custom parameters for a check to be completed\n",
    "stage_parameters = {  # list for checks 3.1, 3.2 custom parameters\n",
    "                     \"between_dash_comparison_list\" : list(),\n",
    "                     # list for check 3.3 custom parameters\n",
    "                     \"dash_to_base_query_list\": list(),\n",
    "                     # list for check 3.4 custom parameters\n",
    "                     \"cumulative_check_list\" : list(),\n",
    "                     # list for checks 3.5 custom parameters\n",
    "                     \"onboard_stat_list\"   : list(), \n",
    "                     # list for check 3.6 custom parameters\n",
    "                     \"business_logic_list\": list() } "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a694db",
   "metadata": {},
   "source": [
    "### Set-up check 3.1, 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605fd0ab",
   "metadata": {},
   "source": [
    "<b> Create the query list for comparing base statistics to dashboard statistics </b> <br>\n",
    "\n",
    "\n",
    "For checking dashboard statistic (non-onboard or cumulative stats - e.g. newly live ecp users or patients) has the same overall sum as the corresponding query for it off base tables. Input parameters required are:\n",
    "> \"dashboard_statistic\":   the dashboard statistic name being checked\n",
    "\n",
    "> \"dash_table\" a string with the name of the dashboard table - assumed to be in the client_dashboard tables database\n",
    "\n",
    "> \"base_statistic_query\" the corresponding base table query for getting the overall sum of the base statisic (e.g. newly live ecp users off fact_users/practitioners)\n",
    "\n",
    ">  \"base_PK_by_pathways\":  If the unique id/entity the statistic is based on for the client -e.g. patients - could be over more than 1 pathway. E.g. a patient on bloom day and bloom night, then\n",
    "      this will result of double-counting of patients when pathway sums added together to compare against select all total. So if this is the case, then need to provide\n",
    "      a query string for getting unique PK ids for statistic (eg patient id) for each pathway. If this is NOT the case, then just provide an empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41202c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################  REQUIRES INPUT FROM ANALYST ######################################################################\n",
    "dashboard_table = \"dashboard_table_name\"\n",
    "\n",
    "# For each statistic that will be tested for sum base <-> dash check, will add logic to base_query_dictionary for obtaining the check against base  \n",
    "# Adding logic for testing active ECP users in dashboard table against base table:\n",
    "stage_parameters[\"dash_to_base_query_list\"].append(\n",
    "{\n",
    "    \"dashboard_statistic\": \"name of statistic\",\n",
    "    \"dash_table\": dashboard_table,\n",
    "    \"base_statistic_query\":     \"\"\"\n",
    "                            SELECT COUNT(DISTINCT column_id) \n",
    "                            FROM BASE_DATABASE.base_table  u \n",
    "                                \"\"\", \n",
    "    \"base_PK_by_pathways\": []\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd62ffd7",
   "metadata": {},
   "source": [
    "### Set-up check 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211b395c",
   "metadata": {},
   "source": [
    "<b> Create the cumulative check list </b> </br>\n",
    "\n",
    "For checking cumulative statistics, ensuring final week/month sum is equal to corresponding base table query sum and additionally select all is also equal. Input parameters are:\n",
    "\n",
    "> i: name of the cumulative statistic in dash table\n",
    "\n",
    "> i. a query string giving the cumulative stat summed grouped by level required for comparison - e.g. by country and pathway - taking max date - e.g. latest total cumulative patients\n",
    "\n",
    "> ii. the summed statistic from base tables - e.g total patients\n",
    "\n",
    "> iii. dictionary key being the name of the dashboard statistic being checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7553aade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################  REQUIRES INPUT FROM ANALYST ######################################################################\n",
    "# setting the cumulative dashboard query to be run for check 3.3 for ecp cumulative\n",
    "cumulative_dash_query = \"\"\"\n",
    "                            -- take the latest cumulative stat for each country then sum up->should be equal to the overall base stat\n",
    "                            SELECT \n",
    "                                SUM(dash_column_name) AS count\n",
    "                            FROM \n",
    "                            DATABASE.TABLE\n",
    "                        \"\"\"\n",
    "base_dash_query =   \"\"\"\n",
    "                        SELECT COUNT(DISTINCT base_id) AS count \n",
    "                        FROM DATABASE_base.TABLE_base\n",
    "                    \"\"\"\n",
    "\n",
    "stage_parameters[\"cumulative_check_list\"].append(\n",
    "{\n",
    "    \"cumulative_dash_statistic\": \"name of dash column\",\n",
    "    \"cumulative_dash_query\": cumulative_dash_query,\n",
    "    \"base_dash_query\": base_dash_query\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cba29c",
   "metadata": {},
   "source": [
    "### Set-up check 3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a7caa3",
   "metadata": {},
   "source": [
    "<b> Create the onboard statistic list  </b> </br>\n",
    "For checking that for 'onboard' statistics where all totals should be the same over pathways and total/select all - e.g. onboarded users - that all levels are the same value, and in addition these are also equal to the corresponding query on the base tables - onboarded users. Input parameters are:\n",
    "\n",
    "> \"dashboard_statistic\": name of onboard statistic in dash table\n",
    "\n",
    ">  \"base_statistic_query\": a query string for the statistic off the base tables\n",
    "\n",
    "> \"dash_table\": the name of the dashboard table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533c0478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################  REQUIRES INPUT FROM ANALYST ######################################################################\n",
    "dashboard_table = \"dash database\"\n",
    "\n",
    "# set-up for newly onboard ecps stat\n",
    "base_dash_query =   \"\"\"\n",
    "                        SELECT COUNT(DISTINCT column_id) \n",
    "                        FROM database.table\n",
    "                    \"\"\"\n",
    "\n",
    "stage_parameters[\"name of dash statistic\"].append(\n",
    "{\n",
    "    \"dashboard_statistic\": \"name of dash statistic\",\n",
    "    \"\"\n",
    "    \"dash_table\": dashboard_table,\n",
    "    \"base_statistic_query\": base_dash_query\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f79053",
   "metadata": {},
   "source": [
    "### Set-up check 3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b91388b",
   "metadata": {},
   "source": [
    "<b> Create the business logic list  </b> </br>\n",
    "For checking that for 'onboard' statistics where all totals should be the same over pathways and total/select all - e.g. onboarded users - that all levels are the same value, and in addition these are also equal to the corresponding query on the base tables - onboarded users. Input parameters are:\n",
    " \n",
    "> \"business_logic_name\": name you want to give to the business logic test - arbitary\n",
    "\n",
    "> \"business_logic_query\" : a query string for the statistic off the base tables\n",
    "\n",
    "> \"base_stat_query\":  the name of the dashboard onboard statiistic as the dictionary key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1447f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################  REQUIRES INPUT FROM ANALYST ######################################################################\n",
    "# Checking total orders off base table is equal to logic off dashboard\n",
    "business_logic_query = \"\"\" \n",
    "                            SELECT \n",
    "                            (\n",
    "                                ( SUM(column1) + SUM(column2) + SUM(column3) ) \n",
    "                                + \n",
    "                                ( SUM(column4)  - SUM(column5) )  -\n",
    "\n",
    "                            )   FROM database.table\n",
    "                            \"\"\"\n",
    "base_stat_query =   \"\"\"\n",
    "                        SELECT COUNT(DISTINCT column_id) \n",
    "                        FROM database.table\n",
    "                    \"\"\"\n",
    "stage_parameters[\"business_logic_list\"].append(\n",
    "{\n",
    "    \"business_logic_name\": \"column 1 + 2 +3 should == column 4 and 5 in dashboard\",\n",
    "    \"business_logic_query\": business_logic_query,\n",
    "    \"base_stat_query\": base_stat_query\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19caeb7",
   "metadata": {},
   "source": [
    "### Set-up check 3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ab4172",
   "metadata": {},
   "source": [
    "<b> Create the between dash comparison list </b> <br>\n",
    " For checking that stats within the dashboard agree where they should e.g. total patients equals cumulative sum of select all for patients. YThough these checks will just check that output of two queries is the same, so can be used for other purposes aswell. Input parameters are:\n",
    "\n",
    "> \"dash_test_name\": the name of the dashboard test - arbitary\n",
    "\n",
    "> \"dash_query_1\": a query string for comparing one dashboard statistic query\n",
    "\n",
    ">  \"dash_query_2\" : the second query string for comparing another dashboard statistic\n",
    "\n",
    ">  \"logical_comparion_operator\": logical operator for wqhat comparsion between two outputs will be completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102676d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################  REQUIRES INPUT FROM ANALYST ######################################################################\n",
    "# Dashboard comparison check 1.  check select all of onboarded ecps is equal to the last date for the cumulative ecps for select all\n",
    "# getting ecps count\n",
    "dash_test_name = \"test name\"\n",
    "dashboard_table = \"dash database\"\n",
    "dash_query_1 =  \"\"\"  \t\n",
    "                    SELECT SUM(dash_column1)\n",
    "                    FROM dash_dbs.dash_tbl\n",
    "                \"\"\"\n",
    "# getting ecps count from cumulative\n",
    "dash_query_2 =  \"\"\"\n",
    "                    SELECT SUM(dash_column2) \n",
    "                    FROM FROM dash_dbs.dash_tbl\n",
    "                    \n",
    "                \"\"\"\n",
    "logical_operator =  \"==\"\n",
    "stage_parameters[\"between_dash_comparison_list\"].append(\n",
    "{\n",
    "    \"dash_test_name\": dash_test_name,\n",
    "    \"dash_query_1\": dash_query_1,\n",
    "    \"dash_query_2\": dash_query_2,\n",
    "    \"logical_comparion_operator\": logical_operator\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cf1916",
   "metadata": {},
   "source": [
    "### Run all Stage 3 Checks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934a8f74",
   "metadata": {},
   "source": [
    "<b> Set up: Create check_set </b> <br>\n",
    "Declare which checks to run for this stage - only checks added as strings below in check_set will be run. \n",
    "> Note: if wanting to skip stage entirely than leave as an empty set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89633b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_set = {'3.1', '3.2', '3.3', '3.4', '3.5', '3.6'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128834c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the stage three checks, for the client using stage one driver function, with no user-defined client inputs required :\n",
    "client_object = stage_3(name='Stage 3', client=client_object, check_set=check_set, **stage_parameters).run_stage_checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ae822c",
   "metadata": {},
   "source": [
    "## Validation Output\n",
    "\n",
    "> will output client validation results and output into slack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe23cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the client, print out the warnings and errors of the validation and send to slack:\n",
    "client_object.output_failures()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('test_final')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f4d2df424717668b5d920ec4f8c7ab904e0a14af76ca1ebcc7059a4069358cb6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
